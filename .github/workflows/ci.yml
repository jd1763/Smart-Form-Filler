name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      # Make imports deterministic and NLTK downloads predictable
      PYTHONPATH: ${{ github.workspace }}:${{ env.PYTHONPATH }}
      NLTK_DATA: ${{ github.workspace }}/.nltk_data

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            backend/requirements.txt

      - name: Show versions & env
        run: |
          python --version
          pip --version
          which python
          echo "PYTHONPATH=$PYTHONPATH"
          echo "NLTK_DATA=$NLTK_DATA"
          python - <<'PY'
import sys, platform, os
print("sys.path[0:5]:", sys.path[:5])
print("platform:", platform.platform())
print("cwd:", os.getcwd())
PY

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          # if you actually rely on backend deps in tests, also install them:
          pip install -r backend/requirements.txt || true

      - name: Prepare NLTK data (local cache)
        run: |
          mkdir -p "$NLTK_DATA"
          python - <<'PY'
import nltk, os
pkgs = ["punkt","punkt_tab","averaged_perceptron_tagger","averaged_perceptron_tagger_eng","stopwords","wordnet","omw-1.4"]
for p in pkgs:
    nltk.download(p, download_dir=os.environ["NLTK_DATA"], quiet=True)
print("NLTK downloaded to:", os.environ["NLTK_DATA"])
PY

      - name: Validate spaCy model (optional but helpful)
        run: |
          python - <<'PY'
import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("hello world")
print("spaCy OK:", [t.text for t in doc])
PY

      - name: Run tests
        run: |
          pytest -vv --maxfail=1

      - name: Run flake8
        run: flake8 .
